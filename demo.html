<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper.cpp Server</title>
    <script src="https://cdn.jsdelivr.net/npm/react/umd/react.development.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.development.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@babel/standalone/babel.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const App = () => {
            const [isRecording, setIsRecording] = React.useState(false);
            const [transcription, setTranscription] = React.useState("");
            const [mediaRecorder, setMediaRecorder] = React.useState(null);
            const [audioChunks, setAudioChunks] = React.useState([]);

            const startRecording = () => {
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        const recorder = new MediaRecorder(stream);
                        setMediaRecorder(recorder);
                        recorder.addEventListener("dataavailable", event => {
                            audioChunks.push(event.data);
                        });
                        recorder.start();
                        setIsRecording(true);
                    })
                    .catch(error => console.error("Error accessing microphone:", error));
            };

            const stopRecording = () => {
                mediaRecorder.stop();
                setIsRecording(false);
                mediaRecorder.addEventListener("stop", () => {
                    const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                    const formData = new FormData();
                    formData.append("file", audioBlob, "recording.wav");
                    fetch("https://whisperapi-production.up.railway.app/inference", {
                        method: "POST",
                        mode: "cors",
                        body: formData
                    })
                    .then(response => response.json())
                    .then(data => setTranscription(data.transcription))
                    .catch(error => console.error("Error:", error));
                    setAudioChunks([]);
                });
            };

            return (
                <div className="container mx-auto p-4">
                    <h1 className="text-4xl font-bold mb-4">Whisper.cpp Server</h1>
                    <div className="mb-8">
                        <button
                            className="px-4 py-2 rounded bg-blue-500 text-white font-semibold focus:outline-none"
                            onClick={isRecording ? stopRecording : startRecording}
                        >
                            {isRecording ? (
                                <><i className="fas fa-stop mr-2"></i>Stop Recording</>
                            ) : (
                                <><i className="fas fa-microphone mr-2"></i>Start Recording</>
                            )}
                        </button>
                    </div>
                    {transcription && (
                        <div className="bg-gray-100 p-4 rounded">
                            <h2 className="text-xl font-semibold mb-2">Transcription:</h2>
                            <p>{transcription}</p>
                        </div>
                    )}
                    <div className="mt-8">
                        <h2 className="text-2xl font-bold mb-4">Server Documentation</h2>
                        <p className="mb-4">To connect to the Whisper.cpp server, use the following endpoints:</p>
                        <ul className="list-disc pl-6 mb-4">
                            <li><strong>/inference</strong>: Send a POST request with the recorded audio file to transcribe the audio.</li>
                            <li><strong>/load</strong>: Send a POST request with the model file to load a specific Whisper model.</li>
                        </ul>
                        <p>Example requests:</p>
                        <pre className="bg-gray-100 p-4 rounded mb-4">
                            # /inference<br />
                            curl https://whisperapi-production.up.railway.app/inference \<br />
                            -H "Content-Type: multipart/form-data" \<br />
                            -F file="@&lt;file-path&gt;" \<br />
                            -F temperature="0.0" \<br />
                            -F temperature_inc="0.2" \<br />
                            -F response_format="json"<br />
                            <br />
                            # /load<br />
                            curl https://whisperapi-production.up.railway.app/load \<br />
                            -H "Content-Type: multipart/form-data" \<br />
                            -F model="&lt;path-to-model-file&gt;"
                        </pre>
                    </div>
                </div>
            );
        };

        ReactDOM.createRoot(document.getElementById("root")).render(<App />);
    </script>
</body>
</html>